# System Tools
import time
# Data Analysis Tools
import numpy as np
import pandas as pd
# Machine Learning Tools
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
# Deep Learning Tools
from tensorflow.keras.optimizers import SGD, Adam, Adagrad, Adamax, Adadelta, RMSprop
# Streamlit Tools
import streamlit as st
# UserDefine Class
from model import DeepLearningModel, MachineLearingModel

# åˆå§‹åŒ–
config_dp = {
    # "dataset": "PHM 2016 Challenge",
    "optimizer": {"optimizer": "Adam",
                  "kwargs": {"beta1": 0.9, "beta2": 0.999, "epsilon": 1e-7}},
    "batch_size": 200,
    "epochs": 2,  # 400,
    "learning_rate": 0.001,
    "loss_function": "mean_squared_error",
    "batch_size_max_value": 798,
    "model": 'Conv1d',
    "graph_granularity": 1,
    "input_shape": (263, 19)
}
config_ml = {
    # "dataset": "PHM 2016 Challenge",
    "model": 'LinearRegression',
    "kwargs": {
        "fit_intercept": True
    }
}
option_layer_initializer = ['Constant', 'GlorotNormal', 'GlorotUniform', 'HeNormal', 'Identity', 'LeCunNormal', 'Ones',
                             'Orthogonal', 'RandomNormal', 'RandomUniform', 'TruncatedNormal', 'VarianceScaling', 'Zeros']
option_activation = ['none', 'Relu', 'Elu', 'Sigmoid', 'Softmax', 'Softplus', 'Tanh', 'Selu', 'Relu6']
option_model_dp = ['Conv1d', 'Conv2d', 'RNN', 'LSTM', 'BiLSTM', 'GRU']
option_model_ml = ['LinearRegression', 'Lasso', 'Ridge', 'ElasticNet', 'BayesianRidge', 'KNN', 'SupportVector', 'DecisionTree',
                   'RandomForest', 'ExtraTree', 'AdaBoost', 'GBDT', 'Xgboost', 'LightGBM']


# load data function
@st.cache
def load_dataset(dataset_name: str, model_type='Conv1d'):
    '''
    dataset_name:str: st.selectbox
    model_type: Default is a deeplearning model
    :return:
    '''

    if dataset_name == 'PHM 2016 Challenge':
        if model_type in option_model_dp:
            # X_train = np.load("/Users/lihan/Workspace/data phm 2016/X_train_r_modeI_chamber4_mm.npy")
            # y_train = np.load("/Users/lihan/Workspace/data phm 2016/y_train_modeI_chamber4_mm.npy")
            # X_test = np.load("/Users/lihan/Workspace/data phm 2016/X_test_r_modeI_chamber4_mm.npy")
            # y_test = np.load("/Users/lihan/Workspace/data phm 2016/y_test_modeI_chamber4_mm.npy")
            X_train = np.load("./data/X_train_r_modeI_chamber4_mm.npy")
            y_train = np.load("./data/y_train_modeI_chamber4_mm.npy")
            X_test = np.load("./data/X_test_r_modeI_chamber4_mm.npy")
            y_test = np.load("./data/y_test_modeI_chamber4_mm.npy")
            return X_train, y_train, X_test, y_test

        elif model_type in option_model_ml:
            # è¯»å–æ—¶çš„ç”¨æ³•
            train_x = pd.read_csv("./data/train_x_mean_modeI_chamber4_mm.csv").set_index('WAFER_ID')
            train_y = pd.read_csv("./data/train_y_mean_modeI_chamber4_mm.csv").set_index('WAFER_ID')
            test_x = pd.read_csv("./data/test_x_mean_modeI_chamber4_mm.csv").set_index('WAFER_ID')
            test_y = pd.read_csv("./data/test_y_mean_modeI_chamber4_mm.csv").set_index('WAFER_ID')
            return train_x, train_y, test_x, test_y


@st.cache
def batch_data_generate(X, y, batch_size):
    '''

    :param X: np.array
    :param y: np.array
    :return: batch_data_list,e.g [(X_1, y_1), ..., (X_n, y_n)]
    '''
    N = y.shape[0] # æ•°æ®æ€»æ•°
    step = int(np.ceil(N/batch_size))
    batch_data_list = []
    for i in range(0, step-1):
        batch_data_list.append((X[i*batch_size:(i+1)*batch_size], y[i*batch_size:(i+1)*batch_size]))
    batch_data_list.append((X[(step-1)*batch_size:], y[(step-1)*batch_size:]))
    return batch_data_list


def st_conv1d(filters, key_name):
    st.number_input(label='Filters', value=filters, format='%d', key=f'num_filters_{key_name}',
                    help='å·ç§¯æ ¸çš„æ•°ç›®ï¼ˆå³è¾“å‡ºçš„ç»´åº¦ï¼‰')
    st.number_input(label='Kernel Size', value=2, format='%d', key=f'num_ker_size_{key_name}',
                    help='æ•´æ•°æˆ–ç”±å•ä¸ªæ•´æ•°æ„æˆçš„list/tupleï¼Œå·ç§¯æ ¸çš„ç©ºåŸŸæˆ–æ—¶åŸŸçª—é•¿åº¦')
    st.number_input(label='Strides', value=1, format='%d', key=f'num_stride_{key_name}',
                    help='æ•´æ•°æˆ–ç”±å•ä¸ªæ•´æ•°æ„æˆçš„list/tupleï¼Œä¸ºå·ç§¯çš„æ­¥é•¿ã€‚')
    st.selectbox(label='Padding',
                 options=['Valid', 'Same', 'Casual'],
                 index=0, key=f'sel_pad_{key_name}',
                 help='è¡¥0ç­–ç•¥ï¼Œâ€œvalidâ€æ„å‘³ç€æ²¡æœ‰å¡«å……ã€‚ â€œsameâ€å¯¼è‡´åœ¨è¾“å…¥çš„å·¦/å³æˆ–ä¸Š/ä¸‹å‡åŒ€å¡«å……é›¶ï¼Œä»¥ä½¿è¾“å‡ºå…·æœ‰ä¸è¾“å…¥ç›¸åŒçš„é«˜åº¦/å®½åº¦å°ºå¯¸ã€‚ â€œcasualâ€å¯¼è‡´å› æœï¼ˆæ‰©å¼ ï¼‰å·ç§¯')
    st.info('â„¹ï¸ Careful: There is no default activation on Conv1D layers')
    st.selectbox(label='Activation',
                 options=option_activation,
                 index=1, key=f'sel_active_{key_name}',
                 help='æ¿€æ´»å‡½æ•°ã€‚å¦‚æœä¸æŒ‡å®šè¯¥å‚æ•°ï¼Œå°†ä¸ä¼šä½¿ç”¨ä»»ä½•æ¿€æ´»å‡½æ•°ï¼ˆå³ä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼ša(x)=xï¼‰')
    st.checkbox(label='Use a Bias', value=True, key=f'check_bias_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œæ˜¯å¦ä½¿ç”¨åç½®é¡¹')
    st.selectbox(label='Bias Initializer',
                 options=option_layer_initializer,
                 index=12, key=f'sel_bias_{key_name}',
                 help='åç½®å‘é‡çš„åˆå§‹åŒ–å™¨')
    st.selectbox(label='Kernel Initializer',
                 options=option_layer_initializer,
                 index=2, key=f'sel_ker_init_{key_name}',
                 help='å†…æ ¸æƒé‡çŸ©é˜µçš„åˆå§‹åŒ–æ–¹æ³•')


def st_conv2d(filters, key_name):
    st.number_input(label='Filters', value=filters, format='%d', key=f'num_filters_{key_name}',
                    help='å·ç§¯æ ¸çš„æ•°ç›®ï¼ˆå³è¾“å‡ºçš„ç»´åº¦ï¼‰')
    st.number_input(label='Kernel Size', value=2, format='%d', key=f'num_ker_size_{key_name}',
                    help='å•ä¸ªæ•´æ•°æˆ–ç”±ä¸¤ä¸ªæ•´æ•°æ„æˆçš„list/tupleï¼Œå·ç§¯æ ¸çš„å®½åº¦å’Œé•¿åº¦ã€‚å¦‚ä¸ºå•ä¸ªæ•´æ•°ï¼Œåˆ™è¡¨ç¤ºåœ¨å„ä¸ªç©ºé—´ç»´åº¦çš„ç›¸åŒé•¿åº¦')
    st.number_input(label='Strides', value=1, format='%d', key=f'num_stride_{key_name}',
                    help='å•ä¸ªæ•´æ•°æˆ–ç”±ä¸¤ä¸ªæ•´æ•°æ„æˆçš„list/tupleï¼Œä¸ºå·ç§¯çš„æ­¥é•¿ã€‚å¦‚ä¸ºå•ä¸ªæ•´æ•°ï¼Œåˆ™è¡¨ç¤ºåœ¨å„ä¸ªç©ºé—´ç»´åº¦çš„ç›¸åŒæ­¥é•¿')
    st.selectbox(label='Padding',
                 options=['Valid', 'Same'],
                 index=1, key=f'sel_pad_{key_name}',
                 help='è¡¥0ç­–ç•¥ï¼Œä¸ºâ€œvalidâ€, â€œsameâ€ ã€‚â€œvalidâ€ä»£è¡¨åªè¿›è¡Œæœ‰æ•ˆçš„å·ç§¯ï¼Œå³å¯¹è¾¹ç•Œæ•°æ®ä¸å¤„ç†ã€‚â€œsameâ€ä»£è¡¨ä¿ç•™è¾¹ç•Œå¤„çš„å·ç§¯ç»“æœï¼Œé€šå¸¸ä¼šå¯¼è‡´è¾“å‡ºshapeä¸è¾“å…¥shapeç›¸åŒ')
    st.info('â„¹ï¸ Careful: There is no default activation on Conv2D layers')
    st.selectbox(label='Activation',
                 options=option_activation,
                 index=1, key=f'sel_active_{key_name}',
                 help='æ¿€æ´»å‡½æ•°ã€‚å¦‚æœä¸æŒ‡å®šè¯¥å‚æ•°ï¼Œå°†ä¸ä¼šä½¿ç”¨ä»»ä½•æ¿€æ´»å‡½æ•°ï¼ˆå³ä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼ša(x)=xï¼‰')
    st.checkbox(label='Use a Bias', value=True, key=f'check_bias_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œæ˜¯å¦ä½¿ç”¨åç½®é¡¹')
    st.selectbox(label='Bias Initializer',
                 options=option_layer_initializer,
                 index=12, key=f'sel_bias_{key_name}',
                 help='åç½®å‘é‡çš„åˆå§‹åŒ–å™¨')
    st.selectbox(label='Kernel Initializer',
                 options=option_layer_initializer,
                 index=2, key=f'sel_ker_init_{key_name}',
                 help='å†…æ ¸æƒé‡çŸ©é˜µçš„åˆå§‹åŒ–æ–¹æ³•')


def st_maxpool1d(poolsize, key_name):
    st.number_input(label='Pool Size', value=poolsize, format='%d', key=f'num_pool_{key_name}',
                    help='æ•´æ•°ï¼Œæ± åŒ–çª—å£å¤§å°')
    st.number_input(label='Strides', value=poolsize, format='%d', key=f'num_stride_{key_name}',
                    help='æ•´æ•°æˆ–Noneï¼Œä¸‹é‡‡æ ·å› å­ï¼Œä¾‹å¦‚è®¾2å°†ä¼šä½¿å¾—è¾“å‡ºshapeä¸ºè¾“å…¥çš„ä¸€åŠï¼Œè‹¥ä¸ºNoneåˆ™é»˜è®¤å€¼ä¸ºpool_size')
    st.selectbox(label='Padding',
                 options=['Valid', 'Same'],
                 index=0, key=f'sel_pad_{key_name}',
                 help=' â€œValidâ€æ„å‘³ç€æ²¡æœ‰å¡«å……ã€‚ â€œSameâ€å¯¼è‡´åœ¨è¾“å…¥çš„å·¦/å³æˆ–ä¸Š/ä¸‹å‡åŒ€å¡«å……ï¼Œä»¥ä½¿è¾“å‡ºå…·æœ‰ä¸è¾“å…¥ç›¸åŒçš„é«˜åº¦/å®½åº¦å°ºå¯¸ã€‚')


def st_maxpool2d(key_name):
    st.number_input(label='Pool Size', value=2, format='%d', key=f'num_pool_{key_name}',
                    help='æ•´æ•°æˆ–é•¿ä¸º2çš„æ•´æ•°tupleï¼Œä»£è¡¨åœ¨ä¸¤ä¸ªæ–¹å‘ï¼ˆç«–ç›´ï¼Œæ°´å¹³ï¼‰ä¸Šçš„ä¸‹é‡‡æ ·å› å­ï¼Œå¦‚å–ï¼ˆ2ï¼Œ2ï¼‰å°†ä½¿å›¾ç‰‡åœ¨ä¸¤ä¸ªç»´åº¦ä¸Šå‡å˜ä¸ºåŸé•¿çš„ä¸€åŠã€‚ä¸ºæ•´æ•°æ„ä¸ºå„ä¸ªç»´åº¦å€¼ç›¸åŒä¸”ä¸ºè¯¥æ•°å­—')
    st.number_input(label='Strides', value=2, format='%d', key=f'num_stride_{key_name}',
                    help='æ•´æ•°æˆ–é•¿ä¸º2çš„æ•´æ•°tupleï¼Œæˆ–è€…Noneï¼Œæ­¥é•¿å€¼')
    st.selectbox(label='Padding',
                 options=['Valid', 'Same'],
                 index=1, key=f'sel_pad_{key_name}',
                 help='â€œValidâ€æ„å‘³ç€æ²¡æœ‰å¡«å……ã€‚ â€œSameâ€å¯¼è‡´åœ¨è¾“å…¥çš„å·¦/å³æˆ–ä¸Š/ä¸‹å‡åŒ€å¡«å……ï¼Œä»¥ä½¿è¾“å‡ºå…·æœ‰ä¸è¾“å…¥ç›¸åŒçš„é«˜åº¦/å®½åº¦å°ºå¯¸ã€‚')


def st_rnn(units, activation, return_seq, key_name):
    st.number_input(label='Units', value=units, min_value=1, format='%d', key=f'num_units_{key_name}',
                    help='æ­£æ•´æ•°ï¼Œè¾“å‡ºç©ºé—´çš„ç»´åº¦')
    st.selectbox(label='Activation',
                 options=option_activation,
                 index=option_activation.index(activation),
                 key=f'sel_active_{key_name}',
                 help='è¦ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ã€‚ å¦‚æœNoneï¼Œåˆ™ä¸åº”ç”¨æ¿€æ´»ï¼ˆå³â€œçº¿æ€§â€æ¿€æ´»ï¼ša(x) = xï¼‰')
    st.checkbox(label='Use a Bias', value=True, key=f'check_bias_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œlayeræ˜¯å¦ä½¿ç”¨åç½®å‘é‡')
    st.selectbox(label='Bias Initializer',
                 options=option_layer_initializer,
                 index=12, key=f'sel_bias_{key_name}',
                 help='åç½®å‘é‡çš„åˆå§‹åŒ–å™¨ã€‚')
    st.selectbox(label='Kernel Initializer',
                 options=option_layer_initializer,
                 index=2, key=f'sel_ker_init_{key_name}',
                 help='å†…æ ¸æƒé‡çŸ©é˜µçš„åˆå§‹åŒ–å™¨ï¼Œç”¨äºè¾“å…¥çš„çº¿æ€§å˜æ¢ã€‚')
    st.checkbox(label='Return Sequences', value=return_seq, key=f'check_return_seq_{key_name}',
                help='å¸ƒå°”å€¼ã€‚ æ˜¯è¿”å›è¾“å‡ºåºåˆ—ä¸­çš„æœ€åä¸€ä¸ªè¾“å‡ºï¼Œè¿˜æ˜¯è¿”å›å®Œæ•´åºåˆ—')
    st.selectbox(label='Recurrent Initializer',
                 options=option_layer_initializer,
                 index=7, key=f'sel_bias_{key_name}',
                 help='å¾ªç¯å†…æ ¸æƒé‡çŸ©é˜µçš„åˆå§‹åŒ–å™¨ï¼Œç”¨äºå¾ªç¯çŠ¶æ€çš„çº¿æ€§å˜æ¢')


def st_lstm(units, activation, recurrent_activation, return_seq, key_name):
    st.number_input(label='Units', value=units, min_value=1, format='%d', key=f'num_units_{key_name}',
                    help='æ­£æ•´æ•°ï¼Œè¾“å‡ºç©ºé—´çš„ç»´åº¦')
    st.selectbox(label='Activation',
                 options=option_activation,
                 index=option_activation.index(activation),
                 key=f'sel_active_{key_name}',
                 help='æ¿€æ´»å‡½æ•°ï¼Œå¦‚æœNoneï¼Œåˆ™ä¸åº”ç”¨æ¿€æ´»ï¼ˆå³â€œçº¿æ€§â€æ¿€æ´»ï¼ša(x) = xï¼‰')
    st.selectbox(label='Recurrent Activation',
                 options=option_activation,
                 index=option_activation.index(recurrent_activation),
                 key=f'sel_recu_active_{key_name}',
                 help='ç”¨äºå¾ªç¯æ­¥éª¤çš„æ¿€æ´»å‡½æ•°ã€‚å¦‚æœNoneï¼Œåˆ™ä¸åº”ç”¨æ¿€æ´»ï¼ˆå³â€œçº¿æ€§â€æ¿€æ´»ï¼ša(x) = xï¼‰')
    st.checkbox(label='Use a Bias', value=True, key=f'check_bias_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œlayeræ˜¯å¦ä½¿ç”¨åç½®å‘é‡')
    st.selectbox(label='Bias Initializer',
                 options=option_layer_initializer,
                 index=12, key=f'sel_bias_{key_name}',
                 help='åç½®å‘é‡çš„åˆå§‹åŒ–å™¨')
    st.selectbox(label='Kernel Initializer',
                 options=option_layer_initializer,
                 index=2, key=f'sel_ker_init_{key_name}',
                 help='å†…æ ¸æƒé‡çŸ©é˜µçš„åˆå§‹åŒ–å™¨ï¼Œç”¨äºè¾“å…¥çš„çº¿æ€§å˜æ¢')
    st.checkbox(label='Return Sequences', value=return_seq, key=f'check_return_seq_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œæ˜¯å¦è¿”å›æœ€åçš„è¾“å‡ºï¼Œåœ¨è¾“å‡ºåºåˆ—æˆ–å®Œæ•´åºåˆ—ä¸­ã€‚')
    st.selectbox(label='Recurrent Initializer',
                 options=option_layer_initializer,
                 index=7, key=f'sel_bias_{key_name}',
                 help='å¾ªç¯æ ¸çš„åˆå§‹åŒ–æ–¹æ³•')


def st_bilstm(units, activation, recurrent_activation, return_seq, key_name):
    st.number_input(label='Units', value=units, min_value=1, format='%d', key=f'num_units_{key_name}',
                    help='æ­£æ•´æ•°ï¼Œè¾“å‡ºç©ºé—´çš„ç»´åº¦')
    st.selectbox(label='Activation',
                 options=option_activation,
                 index=option_activation.index(activation),
                 key=f'sel_active_{key_name}',
                 help='æ¿€æ´»å‡½æ•°ï¼Œå¦‚æœNoneï¼Œåˆ™ä¸åº”ç”¨æ¿€æ´»ï¼ˆå³â€œçº¿æ€§â€æ¿€æ´»ï¼ša(x) = xï¼‰')
    st.selectbox(label='Recurrent Activation',
                 options=option_activation,
                 index=option_activation.index(recurrent_activation),
                 key=f'sel_recu_active_{key_name}',
                 help='ç”¨äºå¾ªç¯æ­¥éª¤çš„æ¿€æ´»å‡½æ•°ã€‚å¦‚æœNoneï¼Œåˆ™ä¸åº”ç”¨æ¿€æ´»ï¼ˆå³â€œçº¿æ€§â€æ¿€æ´»ï¼ša(x) = xï¼‰')
    st.checkbox(label='Use a Bias', value=True, key=f'check_bias_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œlayeræ˜¯å¦ä½¿ç”¨åç½®å‘é‡')
    st.selectbox(label='Bias Initializer',
                 options=option_layer_initializer,
                 index=12, key=f'sel_bias_{key_name}',
                 help='åç½®å‘é‡çš„åˆå§‹åŒ–å™¨')
    st.selectbox(label='Kernel Initializer',
                 options=option_layer_initializer,
                 index=2, key=f'sel_ker_init_{key_name}',
                 help='å†…æ ¸æƒé‡çŸ©é˜µçš„åˆå§‹åŒ–å™¨ï¼Œç”¨äºè¾“å…¥çš„çº¿æ€§å˜æ¢')
    st.checkbox(label='Return Sequences', value=return_seq, key=f'check_return_seq_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œæ˜¯å¦è¿”å›æœ€åçš„è¾“å‡ºï¼Œåœ¨è¾“å‡ºåºåˆ—æˆ–å®Œæ•´åºåˆ—ä¸­ã€‚')
    st.selectbox(label='Recurrent Initializer',
                 options=option_layer_initializer,
                 index=7, key=f'sel_bias_{key_name}',
                 help='å¾ªç¯æ ¸çš„åˆå§‹åŒ–æ–¹æ³•')
    st.selectbox(label='Merge_mode',
                 options=['Sum', 'Mul', 'Concat', 'Ave', 'none'],
                 index=2, key=f'sel_bias_{key_name}',
                 help='ç»„åˆå‰å‘å’Œåå‘RNNçš„è¾“å‡ºçš„æ¨¡å¼ï¼Œå¦‚æœä¸ºNoneï¼Œåˆ™ä¸ä¼šåˆå¹¶è¾“å‡ºï¼Œå®ƒä»¬å°†ä½œä¸ºåˆ—è¡¨è¿”å›')


def st_gru(units, activation, recurrent_activation, return_seq, key_name):
    st.number_input(label='Units', value=units, min_value=1, format='%d', key=f'num_units_{key_name}',
                    help='æ­£æ•´æ•°ï¼Œè¾“å‡ºç©ºé—´çš„ç»´åº¦')
    st.selectbox(label='Activation',
                 options=option_activation,
                 index=option_activation.index(activation),
                 key=f'sel_active_{key_name}',
                 help='æ¿€æ´»å‡½æ•°ï¼Œå¦‚æœNoneï¼Œåˆ™ä¸åº”ç”¨æ¿€æ´»ï¼ˆå³â€œçº¿æ€§â€æ¿€æ´»ï¼ša(x) = xï¼‰')
    st.selectbox(label='Recurrent Activation',
                 options=option_activation,
                 index=option_activation.index(recurrent_activation),
                 key=f'sel_recu_active_{key_name}',
                 help='ç”¨äºå¾ªç¯æ­¥éª¤çš„æ¿€æ´»å‡½æ•°ï¼Œå¦‚æœNoneï¼Œåˆ™ä¸åº”ç”¨æ¿€æ´»ï¼ˆå³â€œçº¿æ€§â€æ¿€æ´»ï¼ša(x) = xï¼‰')
    st.checkbox(label='Use a Bias', value=True, key=f'check_bias_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œå›¾å±‚æ˜¯å¦ä½¿ç”¨åç½®å‘é‡')
    st.selectbox(label='Bias Initializer',
                 options=option_layer_initializer,
                 index=12, key=f'sel_bias_{key_name}',
                 help='åç½®å‘é‡çš„åˆå§‹åŒ–å™¨')
    st.selectbox(label='Kernel Initializer',
                 options=option_layer_initializer,
                 index=2, key=f'sel_ker_init_{key_name}',
                 help='åº”ç”¨äºæ ¸æƒé‡çŸ©é˜µçš„æ­£åˆ™åŒ–å‡½æ•°')
    st.checkbox(label='Return Sequences', value=return_seq, key=f'check_return_seq_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œæ˜¯è¿”å›è¾“å‡ºåºåˆ—ä¸­çš„æœ€åä¸€ä¸ªè¾“å‡ºï¼Œè¿˜æ˜¯è¿”å›å®Œæ•´åºåˆ—ã€‚')
    st.selectbox(label='Recurrent Initializer',
                 options=option_layer_initializer,
                 index=7, key=f'sel_bias_{key_name}',
                 help='å¾ªç¯æ ¸çš„åˆå§‹åŒ–æ–¹æ³•')
    st.checkbox(label='Reset After',
                value=True,
                key=f'check_reset_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œæ˜¯å¦è¿”å›é™¤äº†è¾“å‡ºä¹‹å¤–çš„æœ€åä¸€ä¸ªçŠ¶æ€')


def st_flatten(info):
    # st.info('â„¹ï¸ Will flatten input. i.g.: [28, 28] => [784]')
    st.info(info)


def st_dense(units, activation, key_name):
    st.number_input(label='Units', value=units, min_value=1, key=f'num_units_{key_name}',
                    help='æ­£æ•´æ•°ï¼Œè¾“å‡ºç©ºé—´çš„ç»´åº¦')
    st.selectbox(label='Activation',
                 options=option_activation,
                 index=option_activation.index(activation),
                 key=f'sel_active_{key_name}',
                 help='è¦ä½¿ç”¨çš„æ¿€æ´»åŠŸèƒ½ï¼Œå¦‚æœNoneï¼Œåˆ™ä¸åº”ç”¨ä»»ä½•æ¿€æ´»ï¼ˆå³â€œçº¿æ€§â€æ¿€æ´»ï¼ša(x) = xï¼‰')
    st.selectbox(label='Kernel Initializer',
                 options=option_layer_initializer,
                 index=2, key=f'sel_ker_init_{key_name}',
                 help='å†…æ ¸æƒé‡çŸ©é˜µçš„åˆå§‹åŒ–å™¨')
    st.checkbox(label='Use a Bias', value=True, key=f'check_bias_{key_name}',
                help='å¸ƒå°”å€¼ï¼Œå›¾å±‚æ˜¯å¦ä½¿ç”¨åç½®å‘é‡')
    st.selectbox(label='Bias Initializer',
                 options=option_layer_initializer,
                 index=12, key=f'sel_bias_{key_name}',
                 help='åç½®å‘é‡çš„åˆå§‹åŒ–å™¨')


st.set_page_config(page_title="Deep Learning Model & Machine Learning Model", page_icon="ğŸˆ", layout="wide")


st.session_state = config_dp

with st.sidebar:
    # èœå•ï¼šè¯»å–æ•°æ®/é€‰æ‹©model/è°ƒèŠ‚è¶…å‚æ•°/è®¾ç½®ä¼˜åŒ–å™¨
    with st.expander('Dataset'):
        # é€‰æ‹©æ•°æ®é›†
        dataset_option = st.selectbox(
            label='How would you like to be contacted?',
            options=['PHM 2016 Challenge', 'MNIST', 'FASHION_MNIST', 'CIFAR10', 'QUICK_DRAW10', 'QUICK_DRAW_30'])
        st.session_state['dataset'] = dataset_option
        if dataset_option == 'PHM 2016 Challenge':
            X_train, y_train, X_test, y_test = load_dataset(dataset_name=dataset_option)
            st.write('Total')
            st.write(y_train.shape[0] + y_test.shape[0])
            st.write('Input shape')
            st.write(X_train.shape[1:])
            st.write('Train set')
            st.write(y_train.shape[0])
            st.write('Test set')
            st.write(y_test.shape[0])
            # æ›´æ–°session
            st.session_state['batch_size_max_value'] = y_train.shape[0]
        else:
            st.write('TBC')

    with st.expander('Choose a model'):
        model_radio = st.radio(label='Which kind of model would you like?',
                               options=['Deep Learning Model', 'Traditional Machine Learning Model'])
        if model_radio == 'Deep Learning Model':
            # åˆå§‹åŒ–st.session_state
            st.session_state = config_dp
            # é€‰æ‹©ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹
            model_select = st.selectbox(
                label='Which model would you like to use?',
                options=option_model_dp,
                index=0)
        else:
            # åˆå§‹åŒ–st.session_state
            st.session_state = config_ml
            # é€‰æ‹©ä¸€ç§ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ¨¡å‹
            model_select = st.selectbox(
                label='Which model would you like to use?',
                options=option_model_ml,
                index=0)
        # æ›´æ–°session
        st.session_state['model'] = model_select

    if st.session_state['model'] in option_model_dp:
        # æ·±åº¦å­¦ä¹ æ¨¡å‹
        with st.expander('Hyperparameters'):
            # è°ƒèŠ‚è¶…å‚æ•°
            batch_size = st.number_input(label='BatchSize:',
                                         min_value=1,
                                         max_value=st.session_state['batch_size_max_value'],
                                         step=1,
                                         value=st.session_state['batch_size'],
                                         help='æ•´æ•°ï¼ŒæŒ‡å®šè¿›è¡Œæ¢¯åº¦ä¸‹é™æ—¶æ¯ä¸ªbatchåŒ…å«çš„æ ·æœ¬æ•°ã€‚è®­ç»ƒæ—¶ä¸€ä¸ªbatchçš„æ ·æœ¬ä¼šè¢«è®¡ç®—ä¸€æ¬¡æ¢¯åº¦ä¸‹é™ï¼Œä½¿ç›®æ ‡å‡½æ•°ä¼˜åŒ–ä¸€æ­¥')
            epochs = st.number_input(label='Epochs',
                                     min_value=1,
                                     max_value=1000,
                                     step=10,
                                     value=st.session_state['epochs'],
                                     help='æ•´æ•°ï¼Œè®­ç»ƒçš„è½®æ•°ï¼Œè®­ç»ƒæ•°æ®å°†ä¼šè¢«éå†nb_epochæ¬¡')
            learning_rate = st.number_input(label='LearningRate',
                                            min_value=0.001,
                                            max_value=0.999,
                                            step=0.001,
                                            value=st.session_state['learning_rate'],
                                            format='%.3f',
                                            help='å­¦ä¹ ç‡')
            # æ›´æ–°session
            st.session_state['batch_size'] = batch_size
            st.session_state['epochs'] = epochs
            st.session_state['learning_rate'] = learning_rate

        with st.expander('Optimizer'):
            # è®¾ç½®æŸå¤±å‡½æ•°
            loss_option = st.selectbox(label='Loss Function',
                                       options=['MeanSquaredError'],
                                       index=0,
                                       help='æŸå¤±å‡½æ•°')
            # æ›´æ–°loss_function
            loss_dict = {'MeanSquaredError': 'mean_squared_error'}
            st.session_state['loss_function'] = loss_dict[loss_option]

            # è®¾ç½®ä¼˜åŒ–å™¨
            optimizer_option = st.selectbox(label='Optimizer Function',
                                            options=['Sgd', 'Momentum', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Rmsprop'],
                                            index=4,
                                            help='ä¼˜åŒ–å™¨')
            if optimizer_option == 'Momentum':
                momentum = st.number_input(label='Momentum', min_value=0.0, value=0.0, step=0.01,
                                           help='åŠ¨é‡å‚æ•°ï¼Œå¤§äº0çš„æµ®ç‚¹æ•°ï¼ŒåŠ é€Ÿç›¸å…³æ–¹å‘çš„æ¢¯åº¦ä¸‹é™å¹¶æŠ‘åˆ¶æŒ¯è¡')
                use_nesterov = st.checkbox(label='useNesterov', value=False,
                                           help='ç¡®å®šæ˜¯å¦ä½¿ç”¨NesterovåŠ¨é‡ï¼Œå¸ƒå°”å€¼')
            elif optimizer_option == 'Adagrad':
                initial_accumulator_value = st.number_input(label='InitialAccumulatorValue',
                                                            value=0.1, min_value=0.0, format="%.3f",
                                                                help='æµ®ç‚¹å€¼ï¼Œç´¯åŠ å™¨çš„èµ·å§‹å€¼ï¼ˆæ¯ä¸ªå‚æ•°çš„åŠ¨é‡å€¼ï¼‰ï¼Œå¿…é¡»æ˜¯éè´Ÿæ•°')
            elif optimizer_option == 'Adadelta':
                rho = st.number_input(label='Rho', value=0.95, min_value=0.0, step=0.01,
                                      help='è¡°å‡ç‡')
                epsilon = st.number_input(label='Epsilon', value=1e-7, min_value=0.0, step=1e-7, format="%g",
                                          help='ç”¨äºä¿æŒæ•°å€¼ç¨³å®šæ€§çš„å°æµ®ç‚¹å€¼')
            elif optimizer_option == 'Adam':
                beta1 = st.number_input(label='Beta1', value=0.9, min_value=0.001, max_value=0.999, step=0.05)
                beta2 = st.number_input(label='Beta2', value=0.999, min_value=0.001, max_value=0.999, step=0.005,
                                        format="%.3f")
                epsilon = st.number_input(label='Epsilon', value=1e-7, min_value=0.0, step=1e-7, format="%g")
            elif optimizer_option == 'Adamax':
                beta1 = st.number_input(label='Beta1', value=0.9, min_value=0.001, max_value=0.999, step=0.05,
                                        help='ä¸€é˜¶çŸ©ä¼°è®¡çš„æŒ‡æ•°è¡°å‡ç‡')
                beta2 = st.number_input(label='Beta2', value=0.999, min_value=0.001, max_value=0.999, step=0.005,
                                        format="%.3f", help='äºŒé˜¶çŸ©ä¼°è®¡çš„æŒ‡æ•°è¡°å‡ç‡')
                epsilon = st.number_input(label='Epsilon', value=1e-7, min_value=0.0, step=1e-7, format="%g",
                                          help='æ•°å€¼ç¨³å®šæ€§çš„å°å¸¸æ•°')
                decay = st.number_input(label='Decay', value=0.0, min_value=0.0, step=0.01,
                                        help='å¤§äº0çš„æµ®ç‚¹æ•°ï¼Œæ¯æ¬¡æ›´æ–°åçš„å­¦ä¹ ç‡è¡°å‡å€¼')
            elif optimizer_option == 'Rmsprop':
                decay = st.number_input(label='Decay', value=0.0, min_value=0.0, step=0.01,
                                        help='å¤§äº0çš„æµ®ç‚¹æ•°ï¼Œæ¯æ¬¡æ›´æ–°åçš„å­¦ä¹ ç‡è¡°å‡å€¼')
                momentum = st.number_input(label='Momentum', value=0.0, min_value=0.0, step=0.01,
                                           help='åŠ¨é‡å‚æ•°ï¼Œå¤§äº0çš„æµ®ç‚¹æ•°ï¼ŒåŠ é€Ÿç›¸å…³æ–¹å‘çš„æ¢¯åº¦ä¸‹é™å¹¶æŠ‘åˆ¶æŒ¯è¡')
                epsilon = st.number_input(label='Epsilon', value=1e-7, min_value=0.0, step=1e-7, format="%g",
                                          help='æ•°å€¼ç¨³å®šæ€§çš„å°å¸¸æ•°')
                centered = st.checkbox(label='centered', value=False,
                                       help='å¸ƒå°”å€¼ã€‚ å¦‚æœä¸º Trueï¼Œåˆ™é€šè¿‡æ¢¯åº¦çš„ä¼°è®¡æ–¹å·®å¯¹æ¢¯åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼› å¦‚æœä¸º Falseï¼Œåˆ™é€šè¿‡éå±…ä¸­çš„ç¬¬äºŒæ—¶åˆ»ã€‚ å°†æ­¤è®¾ç½®ä¸º True å¯èƒ½æœ‰åŠ©äºè®­ç»ƒï¼Œä½†åœ¨è®¡ç®—å’Œå†…å­˜æ–¹é¢ç¨è´µä¸€äº›ã€‚ é»˜è®¤ä¸ºå‡')
            # æ˜¾ç¤ºå­¦ä¹ é€Ÿç‡
            st.number_input(label='LearningRate',
                            # value=lr_show,
                            value=st.session_state['learning_rate'],
                            disabled=True)
            st.info('â„¹ï¸ LR is set in the "Hyperparameters tab"')

            if optimizer_option == 'Sgd':
                st.session_state['optimizer'] = {'optimizer': 'Sgd',
                                                 'kwargs': {}}
            elif optimizer_option == 'Momentum':
                st.session_state['optimizer'] = {'optimizer': 'Momentum',
                                                 'kwargs': {'momentum': momentum, 'use_nesterov': use_nesterov}}
            elif optimizer_option == 'Adagrad':
                st.session_state['optimizer'] = {'optimizer': 'Adagrad',
                                                 'kwargs': {'initial_accumulator_value': initial_accumulator_value}}
            elif optimizer_option == 'Adadelta':
                st.session_state['optimizer'] = {'optimizer': 'Adadelta',
                                                 'kwargs': {'rho': rho, 'epsilon': epsilon}}
            elif optimizer_option == 'Adam':
                st.session_state['optimizer'] = {'optimizer': 'Adam',
                                                 'kwargs': {'beta1': beta1, 'beta2': beta2, 'epsilon': epsilon}}
            elif optimizer_option == 'Adamax':
                st.session_state['optimizer'] = {'optimizer': 'Adamax',
                                                 'kwargs': {'beta1': beta1, 'beta2': beta2, 'epsilon': epsilon, 'decay': decay}}
            elif optimizer_option == 'Rmsprop':
                st.session_state['optimizer'] = {'optimizer': 'Rmsprop',
                                                 'kwargs': {'decay': decay, 'momentum': momentum, 'epsilon': epsilon, 'centered': centered}}
        with st.expander('Graph'):
            graph_granularity = st.selectbox(label='Graph Granularity (By Epochs)',
                         options=[1, 5, 10, 20, 40, 100])
            # æ›´æ–°session
            st.session_state['graph_granularity'] = graph_granularity
            # Train loss chart and test metric chart
            train_loss_chart = st.vega_lite_chart(data=None, spec={
                'height': 200,
                'mark': {'type': 'circle', 'tooltip': True},
                'encoding': {
                    'x': {'field': 'Epoch', 'type': 'quantitative'},
                    'y': {'field': 'Train Loss', 'type': 'quantitative'},
                }}, selection={
                "grid": {
                    "type": "interval", "bind": "scales"
                }}, use_container_width=True)
            test_metric_chart = st.vega_lite_chart(data=None, spec={
                'height': 200,
                'mark': {'type': 'circle', 'tooltip': True},
                'encoding': {
                    'x': {'field': 'Epoch', 'type': 'quantitative'},
                    'y': {'field': 'Test Metric', 'type': 'quantitative'},
                }}, selection={
                "grid": {
                    "type": "interval", "bind": "scales"
                }}, use_container_width=True)
    else:
        # ä¼ ç»Ÿæœºå™¨å­¦ä¹ 
        with st.expander('Set Parameters'):
            model_current = st.session_state['model']

            if model_current == 'LinearRegression':
                # LinearRegression()
                fit_intercept = st.checkbox(label='Fit Intercept', value=True, help='æ˜¯å¦è®¡ç®—æ­¤æ¨¡å‹çš„æˆªè·')
                st.session_state['kwargs'] = {'fit_intercept': fit_intercept}

            elif model_current == 'Lasso':
                # Lasso(alpha=0.025)
                alpha = st.number_input(label='Alpha', value=0.025, min_value=0.0001, format='%.4f',
                                help='ä¹˜ä»¥æƒ©ç½šé¡¹çš„å¸¸æ•°')
                st.session_state['kwargs'] = {'alpha': alpha}

            elif model_current == 'Ridge':
                # Ridge(alpha=0.002)
                alpha = st.number_input(label='Alpha', value=0.002, min_value=0.0001, format='%.4f',
                                help='ä¹˜ä»¥æƒ©ç½šé¡¹çš„å¸¸æ•°')
                st.session_state['kwargs'] = {'alpha': alpha}

            elif model_current == 'ElasticNet':
                # ElasticNet(alpha=0.02, l1_ratio=0.7)
                alpha = st.number_input(label='Alpha', value=0.02, min_value=0.0001, format='%.4f',
                                help='ä¹˜ä»¥æƒ©ç½šé¡¹çš„å¸¸æ•°')
                l1_ratio = st.number_input(label='L1 Ratio', value=0.7, min_value=0.0, max_value=1.0, format='%.4f',
                                help='Elastic-Netï¼ˆå¼¹æ€§ç½‘ï¼‰æ··åˆå‚æ•°ï¼Œå–å€¼èŒƒå›´0 <= l1_ratio <= 1')
                st.session_state['kwargs'] = {'alpha': alpha, 'l1_ratio': l1_ratio}

            elif model_current == 'BayesianRidge':
                # BayesianRidge(n_iter=300, alpha_1=1e-9, alpha_2=1e-9, lambda_1=1e-9, lambda_2=1e-9, alpha_init=0.2, compute_score=False)
                n_iter = st.number_input(label='N_iter', value=300, min_value=1, step=1,
                                help='æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚åº”è¯¥å¤§äºæˆ–ç­‰äº1')
                alpha_1 = st.number_input(label='Alpha_1', value=1e-9, format='%g',
                                help='é«˜äºalphaå‚æ•°çš„Gammaåˆ†å¸ƒçš„å½¢çŠ¶å‚æ•°')
                alpha_2 = st.number_input(label='Alpha_2', value=1e-9, format='%g',
                                help='ä¼˜å…ˆäºalphaå‚æ•°çš„Gammaåˆ†å¸ƒçš„åæ¯”ä¾‹å‚æ•°ï¼ˆé€Ÿç‡å‚æ•°ï¼‰')
                lambda_1 = st.number_input(label='Lambda_1', value=1e-9, format='%g',
                                help='é«˜äºlambdaå‚æ•°çš„Gammaåˆ†å¸ƒçš„å½¢çŠ¶å‚æ•°')
                lambda_2 = st.number_input(label='Lambda_2', value=1e-9, format='%g',
                                help='ä¼˜å…ˆäºlambdaå‚æ•°çš„Gammaåˆ†å¸ƒçš„åæ¯”ä¾‹å‚æ•°ï¼ˆé€Ÿç‡å‚æ•°ï¼‰')
                alpha_init = st.number_input(label='Alpha Init', value=0.2, step=0.001, format='%.3f',
                                help='alphaçš„åˆå§‹å€¼ï¼ˆå™ªå£°çš„ç²¾åº¦ï¼‰')
                compute_score = st.checkbox(label='ComputeScore', value=False,
                            help='å¦‚æœä¸ºTrueï¼Œåˆ™è®¡ç®—æ¨¡å‹æ¯ä¸€æ­¥çš„ç›®æ ‡å‡½æ•°')
                st.session_state['kwargs'] = {'n_iter': n_iter, 'alpha_1': alpha_1, 'alpha_2': alpha_2,
                                              'lambda_1': lambda_1, 'lambda_2': lambda_2, 'alpha_init': alpha_init,
                                              'compute_score': compute_score}

            elif model_current == 'KNN':
                # KNeighborsRegressor(n_neighbors=3)
                n_neighbors = st.number_input(label='N_neighbors', value=3, min_value=1, step=1,
                                help='ç”¨äºkneighborsæŸ¥è¯¢çš„ä¸´è¿‘ç‚¹æ•°')
                st.session_state['kwargs'] = {'n_neighbors': n_neighbors}

            elif model_current == 'SupportVector':
                # SVR(kernel='rbf')
                kernel = st.selectbox(label='Kernel',
                             options=['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],
                             index=2,
                             help='æŒ‡å®šç®—æ³•ä¸­ä½¿ç”¨çš„å†…æ ¸ç±»å‹')
                st.session_state['kwargs'] = {'kernel': kernel}

            elif model_current == 'DecisionTree':
                # DecisionTreeRegressor(max_depth=5)
                max_depth = st.number_input(label='Max Depth', value=5, min_value=0, step=1,
                                help='æ ‘çš„æœ€å¤§æ·±åº¦ã€‚å¦‚æœä¸º0ä¹Ÿå°±æ˜¯Noneï¼Œåˆ™å°†èŠ‚ç‚¹å±•å¼€ï¼Œç›´åˆ°æ‰€æœ‰å¶å­éƒ½æ˜¯çº¯å‡€çš„ï¼Œæˆ–è€…ç›´åˆ°æ‰€æœ‰å¶å­éƒ½åŒ…å«å°‘äºmin_samples_splitä¸ªæ ·æœ¬')
                st.session_state['kwargs'] = {'max_depth': max_depth}

            elif model_current == 'RandomForest':
                # RandomForestRegressor(criterion='squared_error', n_estimators=100, random_state=0)
                n_estimators = st.number_input(label='N_Estimators', value=100, min_value=1, step=1,
                               help='æ£®æ—ä¸­æ ‘æœ¨çš„æ•°é‡')
                max_depth = st.number_input(label='Max Depth', value=0, min_value=0, step=1,
                                help='æ ‘çš„æœ€å¤§æ·±åº¦ã€‚å¦‚æœä¸º0ä¹Ÿå°±æ˜¯Noneï¼Œåˆ™å°†èŠ‚ç‚¹å±•å¼€ï¼Œç›´åˆ°æ‰€æœ‰å¶å­éƒ½æ˜¯çº¯å‡€çš„ï¼Œæˆ–è€…ç›´åˆ°æ‰€æœ‰å¶å­éƒ½åŒ…å«å°‘äºmin_samples_splitä¸ªæ ·æœ¬')
                st.session_state['kwargs'] = {'n_estimators': n_estimators,
                                              'max_depth': max_depth}

            elif model_current == 'ExtraTree':
                # ExtraTreesRegressor(n_estimators=50)
                n_estimators = st.number_input(label='N_Estimators', value=50, min_value=1, step=1,
                                help='æ£®æ—ä¸­æ ‘æœ¨çš„æ•°é‡')
                max_depth = st.number_input(label='Max Depth', value=0, min_value=0, step=1,
                                help='æ ‘çš„æœ€å¤§æ·±åº¦ã€‚å¦‚æœä¸º0ä¹Ÿå°±æ˜¯Noneï¼Œåˆ™å°†èŠ‚ç‚¹å±•å¼€ï¼Œç›´åˆ°æ‰€æœ‰å¶å­éƒ½æ˜¯çº¯å‡€çš„ï¼Œæˆ–è€…ç›´åˆ°æ‰€æœ‰å¶å­éƒ½åŒ…å«å°‘äºmin_samples_splitä¸ªæ ·æœ¬')
                st.session_state['kwargs'] = {'n_estimators': n_estimators,
                                              'max_depth': max_depth}

            elif model_current == 'AdaBoost':
                # AdaBoostRegressor(DecisionTreeRegressor(max_depth=5), n_estimators=100, random_state=None)
                max_depth = st.number_input(label='Max Depth', value=5, min_value=0, step=1,
                                help='é»˜è®¤çš„åŸºå­¦ä¹ å™¨DecisionTreeRegressoræ ‘çš„æœ€å¤§æ·±åº¦ã€‚å¦‚æœä¸º0ä¹Ÿå°±æ˜¯Noneï¼Œåˆ™å°†èŠ‚ç‚¹å±•å¼€')
                n_estimators = st.number_input(label='N_Estimators', value=100, min_value=1, step=1,
                                help='ç»ˆæ­¢æ¨è¿›çš„ä¼°è®¡å™¨çš„æœ€å¤§æ•°ç›®ã€‚å¦‚æœå®Œå…¨æ‹Ÿåˆï¼Œå­¦ä¹ è¿‡ç¨‹å°±ä¼šæå‰åœæ­¢ã€‚')
                learning_rate = st.number_input(label='Learning Rate', value=1.0, min_value=0.0001, step=0.001, format='%.4f',
                                help='å­¦ä¹ ç‡,åœ¨æ¯æ¬¡æå‡è¿­ä»£ä¸­åº”ç”¨äºæ¯ä¸ªå›å½’å™¨çš„æƒé‡ã€‚')
                st.session_state['kwargs'] = {'n_estimators': n_estimators,
                                              'max_depth': max_depth,
                                              'learning_rate': learning_rate}

            elif model_current == 'GBDT':
                # GradientBoostingRegressor(n_estimators=50, max_depth=5, learning_rate=0.3)
                n_estimators = st.number_input(label='N_Estimators', value=50, min_value=1, step=1,
                                help='è¦æ‰§è¡Œçš„æ¨è¿›é˜¶æ®µçš„æ•°é‡')
                max_depth = st.number_input(label='Max Depth', value=5, min_value=1, step=1,
                                help='å•ä¸ªå›å½’ä¼°è®¡é‡çš„æœ€å¤§æ·±åº¦')
                learning_rate = st.number_input(label='Learning Rate', value=0.3, min_value=0.0001, step=0.001, format='%.4f',
                                help='å­¦ä¹ ç‡é€šè¿‡learning_rateç¼©å°æ¯æ£µæ ‘çš„è´¡çŒ®')
                st.session_state['kwargs'] = {'n_estimators': n_estimators,
                                              'max_depth': max_depth,
                                              'learning_rate': learning_rate}

            elif model_current == 'Xgboost':
                # XGBRegressor(n_estimators=50, max_depth=5, learning_rate=0.3)
                n_estimators = st.number_input(label='N_Estimators', value=50, min_value=1, step=1,
                                help='æ¢¯åº¦æå‡æ ‘çš„æ•°é‡ã€‚ ç›¸å½“äºæå‡è½®æ•°ã€‚')
                max_depth = st.number_input(label='Max Depth', value=5, min_value=1, step=1,
                                help='åŸºç¡€å­¦ä¹ å™¨çš„æœ€å¤§æ ‘æ·±åº¦')
                learning_rate = st.number_input(label='Learning Rate', value=0.3, min_value=0.0001, step=0.001, format='%.4f',
                                help='å­¦ä¹ ç‡')
                st.session_state['kwargs'] = {'n_estimators': n_estimators,
                                              'max_depth': max_depth,
                                              'learning_rate': learning_rate}

            elif model_current == 'LightGBM':
                # LGBMRegressor(n_estimators=100, max_depth=5, num_leaves=10, learning_rate=0.1)
                n_estimators = st.number_input(label='N_Estimators', value=100, min_value=1, step=1,
                                help='æ¢¯åº¦æå‡æ ‘çš„æ•°é‡')
                max_depth = st.number_input(label='Max Depth', value=5, step=1,
                                help='åŸºç¡€å­¦ä¹ å™¨çš„æœ€å¤§æ ‘æ·±åº¦ï¼Œ<=0 è¡¨ç¤ºæ²¡æœ‰é™åˆ¶ã€‚')
                num_leaves = st.number_input(label='Num Leaves', value=10, min_value=1, step=1,
                                help='åŸºç¡€å­¦ä¹ è€…çš„æœ€å¤§æ ‘å¶')
                learning_rate = st.number_input(label='Learning Rate', value=0.1, min_value=0.0001, step=0.001, format='%.4f',
                                help='å­¦ä¹ ç‡')
                st.session_state['kwargs'] = {'n_estimators': n_estimators,
                                              'max_depth': max_depth,
                                              'num_leaves': num_leaves,
                                              'learning_rate': learning_rate}


st.title("ğŸˆDEEP LEARNING MODEL & MACHINE LEARNING MODEL")
# Run button and Training Log Console
with st.container():
    # st.header('Running Log')
    if st.session_state['model'] in option_model_ml:
        st.info('â„¹ï¸ Dashboard of Loss/Epoch/Batch/ is for deep learning models')
    c_run, c_metric, c_loss, c_epoch, c_batch, c_time = st.columns(6)
    with c_run:
        button_run = st.button('Run')
    with c_metric:
        st.markdown('**Metrics**')
        place_metric = st.empty()
        place_metric.markdown('0')
    with c_loss:
        if st.session_state['model'] in option_model_ml:
            st.markdown('**<font color=#DCDCDC>Loss</font>**', unsafe_allow_html=True)
            place_loss = st.empty()
            place_loss.markdown('<font color=#DCDCDC>0</font>', unsafe_allow_html=True)
        else:
            st.markdown('**Loss**')
            place_loss = st.empty()
            place_loss.markdown('0')
    with c_epoch:
        if st.session_state['model'] in option_model_ml:
            st.markdown('**<font color=#DCDCDC>Epoch</font>**', unsafe_allow_html=True)
            place_epoch = st.empty()
            # place_epoch.markdown(f'<font color=#DCDCDC>0 of {int(st.session_state["epochs"])}</font>',
            #                      unsafe_allow_html=True)
        else:
            st.markdown('**Epoch**')
            place_epoch = st.empty()
            place_epoch.markdown(f'0 of {int(st.session_state["epochs"])}')
    with c_batch:
        if st.session_state['model'] in option_model_ml:
            st.markdown('**<font color=#DCDCDC>Batch</font>**', unsafe_allow_html=True)
            place_batch = st.empty()
            # place_batch.markdown(
            #     f'<font color=#DCDCDC>0 of {int(np.ceil(int(st.session_state["batch_size_max_value"]) / int(st.session_state["batch_size"])))}</font>',
            # unsafe_allow_html=True)
        else:
            st.markdown('**Batch**')
            place_batch = st.empty()
            place_batch.markdown(f'0 of {int(np.ceil(int(st.session_state["batch_size_max_value"]) / int(st.session_state["batch_size"])))}')
    with c_time:
        st.markdown('**Training Time**')
        place_time = st.empty()
        place_time.markdown('0')

# # Train loss chart and test metric chart
# with st.container():
#     c_train_loss, c_test_metric = st.columns(2)
#     with c_train_loss:
#         st.markdown('### Train Loss')
#         train_loss_chart = st.vega_lite_chart(data=None, spec={
#                 'height': 300,
#                 'mark': {'type': 'circle', 'tooltip': True},
#                 'encoding': {
#                     'x': {'field': 'Epoch', 'type': 'quantitative'},
#                     'y': {'field': 'Train Loss', 'type': 'quantitative'},
#             }}, selection={
#                 "grid": {
#                     "type": "interval", "bind": "scales"
#             }}, use_container_width=True)
#     with c_test_metric:
#         st.markdown('### Test Metric')
#         test_metric_chart = st.vega_lite_chart(data=None, spec={
#                 'height': 300,
#                 'mark': {'type': 'circle', 'tooltip': True},
#                 'encoding': {
#                     'x': {'field': 'Epoch', 'type': 'quantitative'},
#                     'y': {'field': 'Test Metric', 'type': 'quantitative'},
#             }}, selection={
#                 "grid": {
#                   "type": "interval", "bind": "scales"
#             }}, use_container_width=True)

# Predicted Chart

container_predict_chart = st.container()
with container_predict_chart:
    st.markdown('### Test Predicted Chart')
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.markdown("###### å‡æ–¹è¯¯å·®MSE")
        place_col1 = st.empty()
        place_col1.metric("Mean Squared Error", "0")
    with col2:
        st.markdown("###### å¹³å‡ç»å¯¹å€¼è¯¯å·®MAE")
        place_col2 = st.empty()
        place_col2.metric("Mean Absolute Error", "0")
    with col3:
        st.markdown("###### å‡æ–¹æ ¹è¯¯å·®RMSE")
        place_col3 = st.empty()
        place_col3.metric("Root Mean Square Error", "0")
    with col4:
        st.markdown("###### å†³å®šç³»æ•°R2 Score")
        place_col4 = st.empty()
        place_col4.metric("R2 Score", "0")
    # predicted chart
    test_predict_chart = st.vega_lite_chart(data=None, spec={
        "height": 300,
        "mark": {'type': "line", 'tooltip': True},
        "encoding": {
            "x": {"field": "Index", "type": "quantitative"},
            "y": {"field": "Value", "type": "quantitative"},
            "color": {"field": "Label",
                      "legend": {"title": None, "direction": "horizontal", "orient": "top"}
                      }
    }}, selection={
        "grid": {
          "type": "interval", "bind": "scales"
    }}, use_container_width=True)

# Console
# with st.container():
#     st.markdown('### Console')
#     st.write(st.session_state)
c_outline, c_content = st.columns((1.5, 2))
with c_outline:
    st.markdown("#### Outline")
    if st.session_state['model'] in option_model_ml:
        st.info('â„¹ï¸ Outline is for deep learning model')
    model_select = st.session_state['model']
    if model_select == 'Conv1d':
        # layer group 1
        with st.expander("Conv1D"):
            st_conv1d(filters=256, key_name='conv1d_layer1')
        with st.expander("MaxPooling1D"):
            st_maxpool1d(poolsize=8, key_name='maxpool1d_layer1')
        # layer group 2
        with st.expander("Conv1D"):
            st_conv1d(filters=128, key_name='conv1d_layer2')
        with st.expander("MaxPooling1D"):
            st_maxpool1d(poolsize=8, key_name='maxpool1d_layer2')
        # layer group 3
        with st.expander("Conv1D"):
            st_conv1d(filters=64, key_name='conv1d_layer3')
        with st.expander("MaxPooling1D"):
            st_maxpool1d(poolsize=2, key_name='maxpool1d_layer3')
        # layer group 4
        with st.expander("Flatten"):
            st_flatten(info='â„¹ï¸ Will flatten input')
        with st.expander("Dense"):
            st_dense(units=16, activation='none', key_name='conv1d_dense1')
        with st.expander("Dense"):
            st_dense(units=1, activation='none', key_name='conv1d_dense2')

    elif model_select == 'Conv2d':
        # intput layer
        with st.expander('InputLayer'):
            st.write('Input Shape')
            st.write(st.session_state['input_shape'])
        # layer group 1
        # exp_layer1_conv2d = st.expander("Conv2D")
        # st_conv2d(exp_layer1_conv2d, filters=16)
        with st.expander("Conv2D"):
            st_conv2d(filters=16, key_name='conv2d_layer1')
        with st.expander("MaxPooling2D"):
            st_maxpool2d(key_name='maxpool2d_layer1')
        # layer group 2
        with st.expander("Conv2D"):
            st_conv2d(filters=32, key_name='conv2d_layer2')
        with st.expander("MaxPooling2D"):
            st_maxpool2d(key_name='maxpool2d_layer2')
        # layer group 3
        with st.expander("Conv2D"):
            st_conv2d(filters=64, key_name='conv2d_layer3')
        with st.expander("MaxPooling2D"):
            st_maxpool2d(key_name='maxpool2d_layer3')
        # layer group 4
        with st.expander("Conv2D"):
            st_conv2d(filters=16, key_name='conv2d_layer4')
        with st.expander("MaxPooling2D"):
            st_maxpool2d(key_name='maxpool2d_layer4')
        # layer group 5
        with st.expander("Flatten"):
            st_flatten('â„¹ï¸ Will flatten input. i.g.: [28, 28] => [784]')
        with st.expander("Dense"):
            st_dense(units=64, activation='Relu', key_name='conv2d_dense1')
        with st.expander("Dense"):
            st_dense(units=16, activation='Relu', key_name='conv2d_dense2')
        with st.expander("Dense"):
            st_dense(units=1, activation='none', key_name='conv2d_dense3')

    elif model_select == 'RNN':
        with st.expander("SimpleRNN"):
            st_rnn(units=40, activation='Tanh', return_seq=True, key_name='rnn_layer1')
        with st.expander("SimpleRNN"):
            st_rnn(units=40, activation='Tanh', return_seq=False, key_name='rnn_layer2')
        with st.expander("Dense"):
            st_dense(units=4, activation='none', key_name='rnn_dense1')
        with st.expander("Dense"):
            st_dense(units=1, activation='none', key_name='rnn_dense2')

    elif model_select == 'LSTM':
        with st.expander("LSTM"):
            st_lstm(units=40, activation='Tanh', recurrent_activation='Sigmoid',
                    return_seq=True, key_name='lstm_layer1')
        with st.expander("LSTM"):
            st_lstm(units=40, activation='Tanh', recurrent_activation='Sigmoid',
                    return_seq=False, key_name='lstm_layer2')
        with st.expander("Dense"):
            st_dense(units=4, activation='none', key_name='lstm_dense1')
        with st.expander("Dense"):
            st_dense(units=1, activation='none', key_name='lstm_dense2')

    elif model_select == 'BiLSTM':
        with st.expander("BidirectionalLSTM"):
            st_bilstm(units=40, activation='Tanh', recurrent_activation='Sigmoid',
                    return_seq=True, key_name='bilstm_layer1')
        with st.expander("BidirectionalLSTM"):
            st_bilstm(units=40, activation='Tanh', recurrent_activation='Sigmoid',
                    return_seq=False, key_name='bilstm_layer2')
        with st.expander("Dense"):
            st_dense(units=4, activation='none', key_name='bilstm_dense1')
        with st.expander("Dense"):
            st_dense(units=1, activation='none', key_name='bilstm_dense2')

    elif model_select == 'GRU':
        with st.expander("GRU"):
            st_gru(units=40, activation='Relu', recurrent_activation='Sigmoid',
                    return_seq=True, key_name='gru_layer1')
        with st.expander("GRU"):
            st_gru(units=40, activation='Relu', recurrent_activation='Sigmoid',
                      return_seq=False, key_name='gru_layer2')
        with st.expander("Dense"):
            st_dense(units=4, activation='none', key_name='gru_dense1')
        with st.expander("Dense"):
            st_dense(units=1, activation='none', key_name='gru_dense2')

with c_content:
    # st.markdown('#### Console')
    expander_log = st.expander("ğŸ’¬ Open log")
    with expander_log:
        # st.write("**Parameters:**")
        # st.write(st.session_state)
        # st.write("**Console:**")
        empty_log = st.empty()

# Button Clicked
if button_run:
    if st.session_state['dataset'] == 'PHM 2016 Challenge':

        with expander_log:
            st.write("**Parameters:**")
            st.write(st.session_state)
            st.write("**Console:**")
            st.write('Start: Hello World')

        model_type = st.session_state['model']
        if model_type in option_model_dp:
            # æ·±åº¦å­¦ä¹ æ¨¡å‹
            # Step0:load data
            X_train, y_train, X_test, y_test = load_dataset(dataset_name=st.session_state['dataset'],
                                                            model_type=model_type)
            if st.session_state['model'] == 'Conv2d':
                # reshapeæ•°æ® to update X_train and X_test
                wafer_number, max_batch_length, variable_number = X_train.shape
                wafer_number_test, max_batch_length, variable_number = X_test.shape
                X_train = X_train.reshape((wafer_number, max_batch_length, variable_number, 1))
                X_test = X_test.reshape((wafer_number_test, max_batch_length, variable_number, 1))
            with expander_log:
                st.write('Step 0: Load data done', X_train.shape, X_test.shape)

            # Step1:define net
            model = DeepLearningModel().init_model(model_type=st.session_state['model'])
            with expander_log:
                st.write('Step 1: Define net done', st.session_state['model'])

            # Step2:compile
            # e.g model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])
            optimizer_str = st.session_state['optimizer']['optimizer']
            optimizer_kwargs = st.session_state['optimizer']['kwargs']
            lr = st.session_state['learning_rate']

            if optimizer_str == 'Sgd':
                opt = SGD(learning_rate=lr)
            elif optimizer_str == 'Momentum':
                opt = SGD(learning_rate=lr,
                          momentum=optimizer_kwargs['momentum'],
                          nesterov=optimizer_kwargs['use_nesterov'])
            elif optimizer_str == 'Adagrad':
                opt = Adagrad(learning_rate=lr,
                              initial_accumulator_value=optimizer_kwargs['initial_accumulator_value'])
            elif optimizer_str == 'Adadelta':
                opt = Adadelta(learning_rate=lr,
                               rho=optimizer_kwargs['rho'],
                               epsilon=optimizer_kwargs['epsilon'])
            elif optimizer_str == 'Adam':
                opt = Adam(learning_rate=lr,
                           beta_1=optimizer_kwargs['beta1'],
                           beta_2=optimizer_kwargs['beta2'],
                           epsilon=optimizer_kwargs['epsilon'])
            elif optimizer_str == 'Adamax':
                opt = Adamax(learning_rate=lr,
                             beta_1=optimizer_kwargs['beta1'],
                             beta_2=optimizer_kwargs['beta2'],
                             epsilon=optimizer_kwargs['epsilon'],
                             decay=optimizer_kwargs['decay'])
            elif optimizer_str == 'Rmsprop':
                opt = RMSprop(learning_rate=lr,
                              decay=optimizer_kwargs['decay'],
                              momentum=optimizer_kwargs['momentum'],
                              epsilon=optimizer_kwargs['epsilon'],
                              centered=optimizer_kwargs['centered'])
            model.compile(loss=st.session_state['loss_function'],
                          optimizer=opt,
                          metrics=['mse'])

            with expander_log:
                st.write('Step 2: Compile done')

            # Step3:fit
            n_epochs = int(st.session_state['epochs'])
            n_batch_size = int(st.session_state['batch_size'])
            n_step = int(np.ceil(int(st.session_state["batch_size_max_value"]) / n_batch_size))
            n_graph_granularity = int(st.session_state['graph_granularity'])
            # Funtion1:å…¨éƒ¨ç›´æ¥è®­ç»ƒ
            # model.fit(X_train, y_train, epochs=n_epochs, batch_size=n_batch_size)
            # st.write('model fit done')
            # Funtion2:åˆ†æ‰¹æ¬¡è®­ç»ƒ
            batch_data_list = batch_data_generate(X_train, y_train, batch_size=n_batch_size)  # åˆ†æ‰¹å‡½æ•°
            t1 = time.time()
            for i in range(0, n_epochs):
                # st.write(f'Epoch {i+1}/{n_epochs}')
                for j, (batch_x, batch_y) in enumerate(batch_data_list):
                    metrics = model.train_on_batch(batch_x, batch_y)
                    t2 = time.time()
                    # st.write(f'{j}: {metrics[0]} -- {t2-t1}')
                    with c_metric:
                        # st.write('Metrics')
                        place_metric.write(f'{metrics[0]:.4f}')
                    with c_loss:
                        # st.write('Loss')
                        place_loss.write(f'{metrics[0]:.4f}')
                    with c_epoch:
                        # st.write('Epoch')
                        place_epoch.write(f'{i+1} of {n_epochs}')
                    with c_batch:
                        # st.write('Batch')
                        place_batch.write(f'{j+1} of {n_step}')
                    with c_time:
                        # st.write('Training Time')
                        place_time.write(f'{(t2-t1)*1000:.0f}ms')
                # plot training loss and predicted metric by epoch graph_granularity
                if (i+1) % n_graph_granularity == 0:
                    y_test_pre_by_epoch = model.predict(X_test)
                    mse_by_epoch = mean_squared_error(y_test, y_test_pre_by_epoch)
                    df_train_loss_tmp = pd.DataFrame({'Epoch': (i+1), 'Train Loss': metrics[0]}, index={0})
                    df_test_metric_tmp = pd.DataFrame({'Epoch': (i+1), 'Test Metric': mse_by_epoch}, index={0})
                    # with c_train_loss:
                    train_loss_chart.add_rows(df_train_loss_tmp)
                    # with c_test_metric:
                    test_metric_chart.add_rows(df_test_metric_tmp)
            with expander_log:
                st.write('Step 3: Train Done')

            # Step4:predict test set
            y_test_pre = model.predict(X_test)
            with expander_log:
                st.write('Step 4: Predict test set done')

            # Step5:compute metrics
            mse = mean_squared_error(y_test, y_test_pre)
            rmse = np.sqrt(mean_squared_error(y_test, y_test_pre))
            mae = mean_absolute_error(y_test, y_test_pre)
            r2 = r2_score(y_test, y_test_pre)
            with expander_log:
                st.write('Compute metrics done')
                st.write(f'mse={mse:.4f}, rmse={rmse:.4f}, mae={mae:.4f}, r2={r2:.4f}')
                st.write('Step 5: Calculate metrics done')

            # Step6:plot predicted curve
            # Solution 1
            # fig = plt.figure(figsize=(15, 4))
            # plt.plot(np.arange(len(y_test)), y_test, color='royalblue', label='Ground Truth') #, linewidth=1.0, linestyle='-')
            # plt.plot(np.arange(len(y_test_pre)), y_test_pre, color='orange', label='Predicted') #, linewidth=1.0, linestyle='-', label='predict value')
            # # plt.title('Prediction Curve')
            # # plt.legend(loc='upper right')
            # plt.title('Test Set Prediction Results');plt.xlabel('No.');plt.ylabel('Value');plt.legend();plt.grid()
            # container_predict_chart.pyplot(fig)
            # Another
            # df_plot = pd.DataFrame(data=np.hstack([y_test, y_test_pre]),
            #                   columns=['Ground Truth', 'Predicted Value'])
            # st.line_chart(df_plot)
            # Solution 2
            # df_plot = pd.DataFrame(data=np.hstack([y_test, y_test_pre]),
            #                   columns=['Ground Truth', 'Predicted Value'])
            # Solution 3
            df_1 = pd.DataFrame(data=enumerate(y_test.reshape(1, -1)[0]),
                                columns=['Index', 'Value'])
            df_1['Label'] = 'Ground Truth'
            df_2 = pd.DataFrame(data=enumerate(y_test_pre.reshape(1, -1)[0]),
                                columns=['Index', 'Value'])
            df_2['Label'] = 'Predicted Value'
            df_plot = pd.concat([df_1, df_2]).reset_index(drop=True)
            with container_predict_chart:
                with col1:
                    place_col1.metric("Mean Absolute Error", f'{mse:.4f}')
                with col2:
                    place_col2.metric("Mean Absolute Error", f'{mae:.4f}')
                with col3:
                    place_col3.metric("Root Mean Square Error", f'{rmse:.4f}')
                with col4:
                    place_col4.metric("R2 Score", f'{r2:.4f}')
                test_predict_chart.add_rows(df_plot)
                # Debug
                # st.table(df_plot.head())
                # st.write(df_plot.shape)
                # st.write(df_3)
                # st.write(type(y_test[0][0]), type(y_test_pre[0][0]))
                # st.write(type(df_1.loc[0,'Index']), type(df_1.loc[0,'Value']))
                # st.write(type(df_2.loc[0, 'Index']), type(df_2.loc[0, 'Value']))
                # st.write(type(df_plot.loc[0, 'Index']), type(df_plot.loc[0, 'Value']))
                # st.write(type(df_plot.loc[0, 'Label']))

                # Print to container
                # st.markdown(f'**Mean Squared Error: {mse:.4f}**')
                # st.markdown(f'**Mean Absolute Error: {mae:.4f}**')
                # st.markdown(f'**Root Mean Squared Error: {rmse:.4f}**')
                # st.markdown(f'**R2 Score: {r2:.4f}**')
            with expander_log:
                st.write('Step 6: Predict Done')

        elif model_type in option_model_ml:
            # æœºå™¨å­¦ä¹ æ¨¡å‹
            # Step 0: load data
            train_x, train_y, test_x, test_y = load_dataset(dataset_name=st.session_state['dataset'],
                                                            model_type=model_type)
            with expander_log:
                st.write('Step 0: Load data done', train_x.shape, train_y.shape)

            # Step 1: init model
            ml_class = MachineLearingModel()
            model = ml_class.init_model(model_type=model_type, **st.session_state['kwargs'])
            with expander_log:
                st.write('Step 1: Init model done')
                st.markdown(f'<font color=#7CFC00>{model_type}</font>', unsafe_allow_html=True)

            # Step 2: fit and predict
            t1 = time.time()
            model, expected, predicted = ml_class.model_fit_predict(model, train_x, train_y.values.reshape(1, -1)[0], test_x, test_y)
            t2 = time.time()
            with c_time:
                # st.write('Training Time')
                place_time.write(f'{(t2 - t1) * 1000:.0f}ms')
            with expander_log:
                st.write('Step 2: fit and predict done')

            # Step 3: compute metrics
            mse = mean_squared_error(expected, predicted)
            rmse = np.sqrt(mean_squared_error(expected, predicted))
            mae = mean_absolute_error(expected, predicted)
            r2 = r2_score(expected, predicted)
            with c_metric:
                # st.write('Metrics')
                place_metric.write(f'{mse:.4f}')
            with expander_log:
                st.write('Step 3: Compute metrics done')
                st.write(f'mse={mse:.4f}, rmse={rmse:.4f}, mae={mae:.4f}, r2={r2:.4f}')

            # Step 4: plot curve
            df_1 = pd.DataFrame(data=enumerate(expected.values.reshape(1,-1)[0]), columns=['Index', 'Value'])
            df_1['Label'] = 'Ground Truth'
            df_2 = pd.DataFrame(data=enumerate(predicted), columns=['Index', 'Value'])
            df_2['Label'] = 'Predicted Value'
            df_plot = pd.concat([df_1, df_2]).reset_index(drop=True)
            with container_predict_chart:
                with col1:
                    place_col1.metric("Mean Absolute Error", f'{mse:.4f}')
                with col2:
                    place_col2.metric("Mean Absolute Error", f'{mae:.4f}')
                with col3:
                    place_col3.metric("Root Mean Square Error", f'{rmse:.4f}')
                with col4:
                    place_col4.metric("R2 Score", f'{r2:.4f}')
                test_predict_chart.add_rows(df_plot)
            with expander_log:
                st.write('Step 4: Plot curve done')
    else:
        with expander_log:
            st.info('â„¹ï¸ TBC')







